# Physical AI & Humanoid Robotics Book

This repository contains the source code and content for the "Physical AI & Humanoid Robotics" book. The book aims to guide developers with a background in Large Language Models (LLMs) into the exciting and complex world of robotics.

## Book Structure

The book is organized into four main parts, each with accompanying hands-on labs:

1.  **The Nervous System (ROS 2)**: Covers the fundamentals of ROS 2 communication patterns, nodes, topics, services, and actions, along with URDF modeling for robot description.
2.  **The Digital Twin (Simulation)**: Explores the use of physics simulators like NVIDIA Isaac Sim for creating realistic digital twins of robots and environments.
3.  **The AI Brain (NVIDIA Isaac)**: Delves into GPU-accelerated perception and navigation using the NVIDIA Isaac ROS platform, including Visual SLAM and Nav2.
4.  **Cognitive Planning (VLMs)**: Focuses on advanced human-robot interaction, leveraging Vision-Language Models (VLMs) and speech-to-text (e.g., Whisper) for high-level command interpretation and action mapping.

## Getting Started

To get started with the book and its code examples, please refer to the `quickstart.md` file in the `specs/001-humanoid-robotics-book/` directory. This document provides instructions for setting up your development environment, building the book's website, and running the lab code.

## Code Examples

The `code/` directory contains ROS 2 workspaces (`lab1_ws`, `lab2_ws`, etc.) corresponding to the hands-on labs in the book. Each lab is designed to be built and run independently, allowing for practical application of the concepts learned.

## Building the Book

The book's content is written in Markdown and built using Docusaurus. You can find the website source in the `book/` directory.

## Contributing

We welcome contributions! If you find any issues, have suggestions for improvements, or would like to add new content or examples, please refer to our contribution guidelines (to be added).

## License

This project is licensed under the Apache-2.0 License.
